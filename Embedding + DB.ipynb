{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-20T15:54:00.330074Z",
     "start_time": "2026-01-20T15:53:55.368901Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import zlib\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as qmodels\n",
    "import time\n",
    "\n",
    "\n",
    "LOCAL_PATH = f\"./qdrant_local_{int(time.time())}\"  # new folder each run to avoid lock\n",
    "client = QdrantClient(path=LOCAL_PATH)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Load chunked dataset\n",
    "# -------------------------\n",
    "CHUNKS_CSV = \"PubMed_chunks.csv\"\n",
    "df = pd.read_csv(CHUNKS_CSV)\n",
    "\n",
    "# Ensure text exists and is clean\n",
    "if \"text\" not in df.columns:\n",
    "    raise ValueError(\"Expected a 'text' column in PubMed_chunks.csv\")\n",
    "\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\").astype(str)\n",
    "df = df[df[\"text\"].str.strip().ne(\"\")].reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# Create stable integer IDs (qid) for Qdrant\n",
    "# -------------------------\n",
    "if \"chunk_id\" in df.columns:\n",
    "    df[\"qid\"] = df[\"chunk_id\"].astype(str).apply(lambda s: zlib.crc32(s.encode(\"utf-8\")))\n",
    "else:\n",
    "    # Fallback: build a stable key from common fields if present\n",
    "    # (PMID + chunk_index + text).\n",
    "    pmid_col = \"PMID\" if \"PMID\" in df.columns else None\n",
    "    chunk_idx_col = \"chunk_index\" if \"chunk_index\" in df.columns else None\n",
    "\n",
    "    def make_key(row):\n",
    "        pmid_part = str(row[pmid_col]) if pmid_col else \"\"\n",
    "        idx_part = str(row[chunk_idx_col]) if chunk_idx_col else \"\"\n",
    "        text_part = row[\"text\"]\n",
    "        return f\"{pmid_part}::{idx_part}::{text_part}\"\n",
    "\n",
    "    df[\"qid\"] = df.apply(lambda r: zlib.crc32(make_key(r).encode(\"utf-8\")), axis=1)\n",
    "\n",
    "# Ensure qid is int (Qdrant local-safe)\n",
    "df[\"qid\"] = df[\"qid\"].astype(int)\n",
    "\n",
    "# Ensure uniqueness; if collisions happen, you’ll catch it here\n",
    "if df[\"qid\"].duplicated().any():\n",
    "    dup = df[df[\"qid\"].duplicated(keep=False)].sort_values(\"qid\")\n",
    "    raise ValueError(\n",
    "        \"Detected duplicate qid values (hash collisions). \"\n",
    "        \"Switch to a stronger ID scheme or include more fields in the hash.\\n\"\n",
    "        f\"Example duplicates:\\n{dup[['qid']].head(10)}\"\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# Embed chunks\n",
    "# -------------------------\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "VECTOR_SIZE = embedder.get_sentence_embedding_dimension()\n",
    "\n",
    "# -------------------------\n",
    "# Create / reset Qdrant collection (LOCAL)\n",
    "# -------------------------\n",
    "COLLECTION = \"pubmed_chunks\"\n",
    "client = QdrantClient(url=\"http://localhost:6333\")  # local storage domain\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION,\n",
    "    vectors_config=qmodels.VectorParams(\n",
    "        size=VECTOR_SIZE,\n",
    "        distance=qmodels.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Upsert in batches\n",
    "# -------------------------\n",
    "batch_size = 256\n",
    "SLEEP_SEC = 0.0  # can set to 0.05 if I want to be extra gentle on my poor laptop lol for later iterations\n",
    "\n",
    "total = len(df)\n",
    "for start in range(0, total, batch_size):\n",
    "    end = min(start + batch_size, total)\n",
    "    batch = df.iloc[start:end]\n",
    "\n",
    "    texts = batch[\"text\"].tolist()\n",
    "    vectors = embedder.encode(\n",
    "        texts,\n",
    "        normalize_embeddings=True,   # cosine-friendly\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "\n",
    "    points = []\n",
    "    for row, vec in zip(batch.to_dict(orient=\"records\"), vectors):\n",
    "        qid = int(row[\"qid\"])\n",
    "\n",
    "        # Payload: keep everything except helper ID column\n",
    "        payload = {k: v for k, v in row.items() if k not in {\"qid\"}}\n",
    "\n",
    "        # Make sure key provenance fields exist if CSV has them\n",
    "        # (No harm if they’re already present.)\n",
    "        payload[\"qid\"] = qid\n",
    "\n",
    "        points.append(\n",
    "            qmodels.PointStruct(\n",
    "                id=qid,\n",
    "                vector=vec.tolist(),\n",
    "                payload=payload\n",
    "            )\n",
    "        )\n",
    "\n",
    "    client.upsert(collection_name=COLLECTION, points=points)\n",
    "\n",
    "    if (start // batch_size) % 10 == 0 or end == total:\n",
    "        print(f\"Indexed {end}/{total} chunks...\")\n",
    "\n",
    "    if SLEEP_SEC:\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "print(f\"✅ Done: embedded + indexed {len(df)} chunks into Qdrant collection '{COLLECTION}'.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/d3ss0n4520v2gt6j9rbttg6h0000gn/T/ipykernel_19239/1508028202.py:73: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 256/1239 chunks...\n",
      "Indexed 1239/1239 chunks...\n",
      "✅ Done: embedded + indexed 1239 chunks into Qdrant collection 'pubmed_chunks'.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T15:56:03.627561Z",
     "start_time": "2026-01-20T15:56:03.547552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing if saved to the localhost.\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "print(client.get_collections())"
   ],
   "id": "10f39fb25dc39b2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='pubmed_chunks')]\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
